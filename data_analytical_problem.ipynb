{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encounter errors in the code, update the packages\n",
    "# !pip install scipy==1.10.1\n",
    "# !pip install numpy==1.21.2\n",
    "# !pip install pandas==1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from saver_func import SaveData\n",
    "\n",
    "save = SaveData.save\n",
    "\n",
    "# display options for numpy and pandas\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "You will have **30** total minutes to look through four tasks (10 for tasks 0 and 1, 10 for task 2, and 10 for task 3). Your goal is to understand the purpose of the code and also why the code's author made the choices they did as best as you can. If you run out of time on a given task, that’s okay and we will move onto the next task regardless.\n",
    "\n",
    "You may write code and check documentation to better understand the code cells. Furthermore, we have implemented a function `save()` which takes two arguments, a DataFrame/Series and optionally a suffix for the file. An example using `Task 0` is seen here:\n",
    "\n",
    "> ```python\n",
    "> buoy_raw = pd.read_csv(fp, sep='\\s+')\n",
    "> save(buoy_raw, \"raw\")\n",
    "> buoy = buoy_raw.dropna()\n",
    "> ```\n",
    "\n",
    "You are welcome to run the cells as many times as you need. Further, you may use the `save()` function as many times as you see fit. If you edit any lines, the original code is hidden in a markdown cell at the top of the notebook.\n",
    "\n",
    "We will interrupt you after 10 minutes to prompt you to complete a [short survey](https://forms.gle/7jdxEDTrbd1EVRHT9) and move on to the next section. If you finish a section early, let us know before you move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You have joined a lab at the Scripps Institution of Oceanography. Your coworker, Alex, was tasked to make a quick analysis on a dataset and has since left for vacation. Your boss has asked you to get familiar with Alex's code in order to make additional analysis. Unfortunately for you, their code lacks comments or much neatness. Become familiar with Alex's code for future analysis. Subject matter is not necessary for the analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Broadly, the four tasks are as follows\n",
    "- **Task 0**: Clean the dataset\n",
    "- **Task 1**: Assess missingness\n",
    "    - Definition: Data is considered \"missing at random\" if the chance that a value is missing depends on other columns, but not the actual missing value itself.\n",
    "- **Task 2**: Imputation\n",
    "- **Task 3**: Compare imputation to original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alex's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/0y/gbwmzjp93k12t06yhk8_2p7h0000gn/T/ipykernel_40260/1803450607.py:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  buoy_raw = pd.read_csv(fp, sep=\"\\s+\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>T1</th>\n",
       "      <th>TIME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>...</th>\n",
       "      <th>WWH</th>\n",
       "      <th>WWP</th>\n",
       "      <th>WWD</th>\n",
       "      <th>STEEPNESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46275</td>\n",
       "      <td>B</td>\n",
       "      <td>2100</td>\n",
       "      <td>33.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>5.6</td>\n",
       "      <td>W</td>\n",
       "      <td>SWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46086</td>\n",
       "      <td>B</td>\n",
       "      <td>2100</td>\n",
       "      <td>32.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHIP</td>\n",
       "      <td>S</td>\n",
       "      <td>2100</td>\n",
       "      <td>33.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46025</td>\n",
       "      <td>B</td>\n",
       "      <td>2110</td>\n",
       "      <td>33.76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46025</td>\n",
       "      <td>B</td>\n",
       "      <td>2100</td>\n",
       "      <td>33.76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>MBXC1</td>\n",
       "      <td>O</td>\n",
       "      <td>910</td>\n",
       "      <td>35.37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>MBXC1</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>35.37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>46259</td>\n",
       "      <td>B</td>\n",
       "      <td>956</td>\n",
       "      <td>34.77</td>\n",
       "      <td>...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NW</td>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>46259</td>\n",
       "      <td>B</td>\n",
       "      <td>926</td>\n",
       "      <td>34.77</td>\n",
       "      <td>...</td>\n",
       "      <td>8.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NW</td>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>SHIP</td>\n",
       "      <td>S</td>\n",
       "      <td>900</td>\n",
       "      <td>34.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2496 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          D T1  TIME    LAT  ...   WWH  WWP  WWD STEEPNESS\n",
       "0     46275  B  2100  33.29  ...  1.97  5.6    W     SWELL\n",
       "1     46086  B  2100   32.5  ...   NaN  NaN  NaN       NaN\n",
       "2      SHIP  S  2100   33.6  ...   NaN  NaN  NaN       NaN\n",
       "3     46025  B  2110  33.76  ...   NaN  NaN  NaN       NaN\n",
       "4     46025  B  2100  33.76  ...   NaN  NaN  NaN       NaN\n",
       "...     ... ..   ...    ...  ...   ...  ...  ...       ...\n",
       "2491  MBXC1  O   910  35.37  ...   NaN  NaN  NaN       NaN\n",
       "2492  MBXC1  O   900  35.37  ...   NaN  NaN  NaN       NaN\n",
       "2493  46259  B   956  34.77  ...   8.2  7.7   NW   AVERAGE\n",
       "2494  46259  B   926  34.77  ...  8.86  9.9   NW   AVERAGE\n",
       "2495   SHIP  S   900   34.6  ...   NaN  NaN  NaN       NaN\n",
       "\n",
       "[2496 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TASK 0\n",
    "\n",
    "# Link to txt file: https://raw.githubusercontent.com/ch-lum/table_information/main/buoy.txt\n",
    "# Link to schema: https://www.ndbc.noaa.gov/obsdes.shtml\n",
    "\n",
    "fp = \"buoy.txt\"\n",
    "buoy_raw = pd.read_csv(fp, sep=\"\\s+\")\n",
    "buoy = buoy_raw.dropna()\n",
    "buoy = buoy.replace(r\"-+$\", np.nan, regex=True)\n",
    "buoy = buoy[buoy[\"TIME\"] != \"TIME\"]\n",
    "buoy = buoy.dropna(axis=1, how=\"all\").reset_index(drop=True)\n",
    "non_numeric_cols = set([\"D\", \"T1\", \"SwD\", \"WWD\", \"STEEPNESS\"])\n",
    "numeric_cols = list(set(buoy.columns) - non_numeric_cols)\n",
    "buoy.loc[:, numeric_cols] = buoy.loc[:, numeric_cols].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m missingness \u001b[38;5;241m=\u001b[39m cont_tables\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: stats\u001b[38;5;241m.\u001b[39mchi2_contingency(x)\u001b[38;5;241m.\u001b[39mpvalue \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m present_props \u001b[38;5;241m=\u001b[39m present_counts\u001b[38;5;241m.\u001b[39mdiv(totals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpresent_props\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maxhline(\n\u001b[1;32m     17\u001b[0m     y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m missingness\n",
      "File \u001b[0;32m/opt/anaconda3/envs/code_comprehension_user_study_env/lib/python3.13/site-packages/pandas/plotting/_core.py:947\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 947\u001b[0m     plot_backend \u001b[38;5;241m=\u001b[39m \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     x, y, kind, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_args(\n\u001b[1;32m    950\u001b[0m         plot_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, args, kwargs\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    953\u001b[0m     kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind_aliases\u001b[38;5;241m.\u001b[39mget(kind, kind)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/code_comprehension_user_study_env/lib/python3.13/site-packages/pandas/plotting/_core.py:1944\u001b[0m, in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m   1942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[0;32m-> 1944\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1945\u001b[0m _backends[backend_str] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m/opt/anaconda3/envs/code_comprehension_user_study_env/lib/python3.13/site-packages/pandas/plotting/_core.py:1874\u001b[0m, in \u001b[0;36m_load_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.plotting._matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m-> 1874\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1875\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib is required for plotting when the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1876\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault backend \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is selected.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1877\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[1;32m   1880\u001b[0m found_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "### TASK 1\n",
    "\n",
    "totals = buoy[\"T1\"].value_counts()\n",
    "missing_some = buoy.drop(buoy.columns[~buoy.isnull().any()].drop(\"T1\"), axis=1)\n",
    "present_counts = missing_some.groupby(\"T1\").count()\n",
    "cont_tables = present_counts.melt(ignore_index=False).rename(\n",
    "    columns={\"value\": \"Present\"}\n",
    ")\n",
    "cont_tables[\"Missing\"] = cont_tables.groupby(\"variable\")[\"Present\"].transform(\n",
    "    lambda x: totals - x\n",
    ")\n",
    "missingness = cont_tables.groupby(\"variable\").apply(\n",
    "    lambda x: stats.chi2_contingency(x).pvalue < 0.0001\n",
    ")\n",
    "present_props = present_counts.div(totals, axis=0)\n",
    "present_props.T.plot(kind=\"bar\").axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"--\", linewidth=0.5\n",
    ")\n",
    "\n",
    "missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 2\n",
    "\n",
    "no_ships = buoy.groupby(\"T1\").filter(lambda x: len(x) > 200)\n",
    "melted = no_ships.melt(id_vars=\"T1\", ignore_index=False)\n",
    "melted = melted.groupby(\"variable\").filter(\n",
    "    lambda x: x.groupby(\"T1\")[\"value\"].count().min() > 200\n",
    ")\n",
    "un_melted = melted.reset_index().pivot(\n",
    "    index=\"index\", columns=\"variable\", values=\"value\"\n",
    ")\n",
    "no_ships = pd.concat([no_ships[\"T1\"], un_melted], axis=1).reset_index(drop=True)\n",
    "quantiles = pd.qcut(no_ships[\"TIME\"], 25)\n",
    "missing_cols = no_ships.isnull().any()\n",
    "means = no_ships.groupby([quantiles, \"T1\"])[no_ships.columns[missing_cols]].mean()\n",
    "imputation = (\n",
    "    pd.merge(\n",
    "        no_ships.set_index([quantiles, \"T1\"]).loc[:, \"D\"],\n",
    "        means,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    .loc[:, missing_cols]\n",
    "    .reset_index()\n",
    ")\n",
    "imputed = no_ships.copy()\n",
    "imputed.loc[:, missing_cols] = no_ships.loc[:, missing_cols].combine_first(\n",
    "    imputation.loc[:, missing_cols]\n",
    ")\n",
    "\n",
    "imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 3\n",
    "\n",
    "together = pd.concat([imputed, no_ships], keys=[\"imputed\", \"original\"])\n",
    "together = together[(together[\"TIME\"] >= 900) & (together[\"TIME\"] <= 2100)]\n",
    "together = together[[\"TIME\", \"WDIR\"]]\n",
    "together.loc[:, \"WDIR_adj\"] = (together[\"WDIR\"] + (360 / 16 / 2)) % 360\n",
    "together = together.reset_index()\n",
    "directions = pd.cut(\n",
    "    together[\"WDIR_adj\"], bins=np.linspace(0, 360, 17), include_lowest=True\n",
    ")\n",
    "hours = together[\"TIME\"] // 100\n",
    "d_h = together.pivot_table(\n",
    "    index=[\"level_0\", hours],\n",
    "    columns=directions,\n",
    "    values=\"TIME\",\n",
    "    aggfunc=\"count\",\n",
    ")\n",
    "d_h.columns = [\n",
    "    \"N\",\n",
    "    \"NNE\",\n",
    "    \"NE\",\n",
    "    \"ENE\",\n",
    "    \"E\",\n",
    "    \"ESE\",\n",
    "    \"SE\",\n",
    "    \"SSE\",\n",
    "    \"S\",\n",
    "    \"SSW\",\n",
    "    \"SW\",\n",
    "    \"WSW\",\n",
    "    \"W\",\n",
    "    \"WNW\",\n",
    "    \"NW\",\n",
    "    \"NNW\",\n",
    "]\n",
    "d_h = d_h.fillna(0)\n",
    "d_h_props = d_h.div(d_h.sum(axis=1), axis=0)\n",
    "\n",
    "for key in d_h.index.levels[0]:\n",
    "    axes = d_h_props.xs(key).plot(kind=\"area\", colormap=\"twilight_shifted\")\n",
    "    axes.set_title(key)\n",
    "    axes.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code (in markdown)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "################################################################\n",
    "\n",
    "### TASK 0\n",
    "\n",
    "# Link to txt file: https://raw.githubusercontent.com/ch-lum/table_information/main/buoy.txt\n",
    "# Link to schema: https://www.ndbc.noaa.gov/obsdes.shtml\n",
    "\n",
    "fp = 'buoy.txt'\n",
    "buoy_raw = pd.read_csv(fp, sep='\\s+')\n",
    "buoy = buoy_raw.dropna()\n",
    "buoy = buoy.replace(r\"-+$\", np.nan, regex=True)\n",
    "buoy = buoy[buoy[\"TIME\"] != \"TIME\"]\n",
    "buoy = buoy.dropna(axis=1, how='all').reset_index(drop=True)\n",
    "buoy.iloc[:, 2:-5] = buoy.iloc[:, 2:-5].apply(pd.to_numeric, errors='coerce')\n",
    "buoy.iloc[:, -4:-2] = buoy.iloc[:, -4:-2].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "buoy\n",
    "\n",
    "################################################################\n",
    "\n",
    "### TASK 1\n",
    "\n",
    "totals = buoy[\"T1\"].value_counts()\n",
    "missing_some = buoy.drop(buoy.columns[~buoy.isnull().any()].drop(\"T1\"), axis=1)\n",
    "present_counts = missing_some.groupby(\"T1\").count()\n",
    "cont_tables = present_counts.melt(ignore_index=False).rename(\n",
    "    columns={\"value\": \"Present\"}\n",
    ")\n",
    "cont_tables[\"Missing\"] = cont_tables.groupby(\"variable\")[\"Present\"].transform(\n",
    "    lambda x: totals - x\n",
    ")\n",
    "missingness = cont_tables.groupby(\"variable\").apply(\n",
    "    lambda x: stats.chi2_contingency(x).pvalue< 0.0001\n",
    ")\n",
    "present_props = present_counts.div(totals, axis=0)\n",
    "present_props.T.plot(kind=\"bar\").axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"--\", linewidth=0.5\n",
    ")\n",
    "\n",
    "missingness\n",
    "\n",
    "################################################################\n",
    "\n",
    "### TASK 2\n",
    "\n",
    "no_ships = buoy.groupby(\"T1\").filter(lambda x: len(x) > 200)\n",
    "melted = no_ships.melt(id_vars=\"T1\", ignore_index=False)\n",
    "melted = melted.groupby(\"variable\").filter(\n",
    "    lambda x: x.groupby(\"T1\")[\"value\"].count().min() > 200\n",
    ")\n",
    "un_melted = melted.reset_index().pivot(\n",
    "    index=\"index\", columns=\"variable\", values=\"value\"\n",
    ")\n",
    "no_ships = pd.concat([no_ships[\"T1\"], un_melted], axis=1).reset_index(drop=True)\n",
    "quantiles = pd.qcut(no_ships[\"TIME\"], 25)\n",
    "missing_cols = no_ships.isnull().any()\n",
    "means = no_ships.groupby([quantiles, \"T1\"])[\n",
    "    no_ships.columns[missing_cols]\n",
    "].mean()\n",
    "imputation = (\n",
    "    pd.merge(\n",
    "        no_ships.set_index([quantiles, \"T1\"]).loc[:, \"D\"],\n",
    "        means,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    .loc[:, missing_cols]\n",
    "    .reset_index()\n",
    ")\n",
    "imputed = no_ships.copy()\n",
    "imputed.loc[:, missing_cols] = no_ships.loc[:, missing_cols].combine_first(\n",
    "    imputation.loc[:, missing_cols]\n",
    ")\n",
    "\n",
    "imputed\n",
    "\n",
    "################################################################\n",
    "\n",
    "### TASK 3\n",
    "\n",
    "together = pd.concat([imputed, no_ships], keys=[\"imputed\", \"original\"])\n",
    "together = together[(together[\"TIME\"] >= 900) & (together[\"TIME\"] <= 2100)]\n",
    "together = together[[\"TIME\", \"WDIR\"]]\n",
    "together.loc[:, \"WDIR_adj\"] = (together[\"WDIR\"] + (360 / 16 / 2)) % 360\n",
    "together = together.reset_index()\n",
    "directions = pd.cut(\n",
    "    together[\"WDIR_adj\"], bins=np.linspace(0, 360, 17), include_lowest=True\n",
    ")\n",
    "hours = together[\"TIME\"] // 100\n",
    "d_h = together.pivot_table(\n",
    "    index=[\"level_0\", hours],\n",
    "    columns=directions,\n",
    "    values=\"TIME\",\n",
    "    aggfunc=\"count\",\n",
    ")\n",
    "d_h.columns = [\n",
    "    \"N\",\n",
    "    \"NNE\",\n",
    "    \"NE\",\n",
    "    \"ENE\",\n",
    "    \"E\",\n",
    "    \"ESE\",\n",
    "    \"SE\",\n",
    "    \"SSE\",\n",
    "    \"S\",\n",
    "    \"SSW\",\n",
    "    \"SW\",\n",
    "    \"WSW\",\n",
    "    \"W\",\n",
    "    \"WNW\",\n",
    "    \"NW\",\n",
    "    \"NNW\",\n",
    "]\n",
    "d_h = d_h.fillna(0)\n",
    "d_h_props = d_h.div(d_h.sum(axis=1), axis=0)\n",
    "\n",
    "for key in d_h.index.levels[0]:\n",
    "    axes = d_h_props.xs(key).plot(kind=\"area\", colormap=\"twilight_shifted\")\n",
    "    axes.set_title(key)\n",
    "    axes.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_comprehension_user_study_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
